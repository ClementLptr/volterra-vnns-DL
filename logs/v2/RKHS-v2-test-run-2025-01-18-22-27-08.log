2025-01-18 22:27:08,109 - INFO - Logging initialized. Log file: /usr/users/volterrakernel/lepretre_cle/volterra/logs/v2/RKHS-v2-test-run-2025-01-18-22-27-08.log
2025-01-18 22:27:08,109 - INFO - Model version: v2
2025-01-18 22:27:08,191 - INFO - Using device: cuda:0
2025-01-18 22:27:08,192 - DEBUG - Initializing architecture configuration.
2025-01-18 22:27:08,192 - DEBUG - Calculating feature dimensions dynamically.
2025-01-18 22:27:08,192 - DEBUG - Initial input dimensions: 16x112x112
2025-01-18 22:27:08,192 - DEBUG - After layer with stride 1: 16x112x112
2025-01-18 22:27:08,192 - DEBUG - After layer with stride 2: 8x56x56
2025-01-18 22:27:08,192 - DEBUG - After layer with stride 1: 8x56x56
2025-01-18 22:27:08,192 - DEBUG - After layer with stride 2: 4x28x28
2025-01-18 22:27:08,192 - DEBUG - Initializing layers.
2025-01-18 22:27:08,711 - DEBUG - Initialized eta_1 with shape: torch.Size([3, 27, 27, 16, 112, 112])
2025-01-18 22:27:09,190 - DEBUG - Initialized eta_2 with shape: torch.Size([3, 27, 27, 16, 112, 112])
2025-01-18 22:27:09,671 - DEBUG - Initialized eta_3 with shape: torch.Size([3, 27, 27, 16, 112, 112])
2025-01-18 22:27:10,150 - DEBUG - Initialized eta_4 with shape: torch.Size([3, 27, 27, 16, 112, 112])
2025-01-18 22:27:10,151 - DEBUG - Initialized BatchNorm3d and Dropout3d for layer 1
2025-01-18 22:27:10,151 - DEBUG - Initialized BatchNorm3d and Dropout3d for layer 2
2025-01-18 22:27:10,151 - DEBUG - Initialized BatchNorm3d and Dropout3d for layer 3
2025-01-18 22:27:10,151 - DEBUG - Initialized BatchNorm3d and Dropout3d for layer 4
2025-01-18 22:27:10,151 - DEBUG - Initializing weights for all layers.
2025-01-18 22:27:10,151 - DEBUG - Initializing architecture configuration.
2025-01-18 22:27:10,151 - DEBUG - Calculating feature dimensions dynamically.
2025-01-18 22:27:10,152 - DEBUG - Initial input dimensions: 16x112x112
2025-01-18 22:27:10,152 - DEBUG - After layer with stride 1: 16x112x112
2025-01-18 22:27:10,152 - DEBUG - After layer with stride 2: 8x56x56
2025-01-18 22:27:10,152 - DEBUG - After layer with stride 1: 8x56x56
2025-01-18 22:27:10,152 - DEBUG - After layer with stride 2: 4x28x28
2025-01-18 22:27:10,152 - DEBUG - Initializing layers.
2025-01-18 22:27:10,486 - DEBUG - Initialized eta_1 with shape: torch.Size([2, 27, 27, 16, 112, 112])
2025-01-18 22:27:10,810 - DEBUG - Initialized eta_2 with shape: torch.Size([2, 27, 27, 16, 112, 112])
2025-01-18 22:27:11,133 - DEBUG - Initialized eta_3 with shape: torch.Size([2, 27, 27, 16, 112, 112])
2025-01-18 22:27:11,461 - DEBUG - Initialized eta_4 with shape: torch.Size([2, 27, 27, 16, 112, 112])
2025-01-18 22:27:11,461 - DEBUG - Initialized BatchNorm3d and Dropout3d for layer 1
2025-01-18 22:27:11,461 - DEBUG - Initialized BatchNorm3d and Dropout3d for layer 2
2025-01-18 22:27:11,461 - DEBUG - Initialized BatchNorm3d and Dropout3d for layer 3
2025-01-18 22:27:11,462 - DEBUG - Initialized BatchNorm3d and Dropout3d for layer 4
2025-01-18 22:27:11,462 - DEBUG - Initializing weights for all layers.
2025-01-18 22:27:13,450 - INFO - Total model parameters: 2939.85M
2025-01-18 22:27:15,793 - INFO - TensorBoard log directory: /usr/users/volterrakernel/lepretre_cle/volterra/models/Jan18_22-27-15_sh03
2025-01-18 22:27:15,794 - INFO - Dataset: hmdb51, Root: ./data/HMDB51/videos, Output: ./data/HMDB51/preprocessed
2025-01-18 22:27:15,794 - DEBUG - Checking preprocessing for hmdb51
2025-01-18 22:27:16,482 - DEBUG - Preprocessing check passed
2025-01-18 22:27:16,540 - INFO - Number of train videos: 4289
2025-01-18 22:27:16,546 - INFO - Dataset: hmdb51, Root: ./data/HMDB51/videos, Output: ./data/HMDB51/preprocessed
2025-01-18 22:27:16,546 - DEBUG - Checking preprocessing for hmdb51
2025-01-18 22:27:16,788 - DEBUG - Preprocessing check passed
2025-01-18 22:27:16,815 - INFO - Number of val videos: 1101
2025-01-18 22:27:16,821 - INFO - Dataset: hmdb51, Root: ./data/HMDB51/videos, Output: ./data/HMDB51/preprocessed
2025-01-18 22:27:16,821 - DEBUG - Checking preprocessing for hmdb51
2025-01-18 22:27:17,100 - DEBUG - Preprocessing check passed
2025-01-18 22:27:17,128 - INFO - Number of test videos: 1376
2025-01-18 22:27:17,133 - INFO - Starting epoch 1/100
2025-01-18 22:27:18,448 - DEBUG - Starting forward pass.
2025-01-18 22:27:18,465 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:18,467 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:18,467 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:18,807 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:19,098 - DEBUG - Starting forward pass.
2025-01-18 22:27:19,098 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:19,098 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:19,099 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:19,420 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:19,701 - DEBUG - Starting forward pass.
2025-01-18 22:27:19,701 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:19,702 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:19,702 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:20,026 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:20,326 - DEBUG - Starting forward pass.
2025-01-18 22:27:20,327 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:20,327 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:20,327 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:20,655 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:20,968 - DEBUG - Starting forward pass.
2025-01-18 22:27:20,968 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:20,968 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:20,969 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:21,300 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:21,581 - DEBUG - Starting forward pass.
2025-01-18 22:27:21,582 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:21,582 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:21,582 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:21,903 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:22,235 - DEBUG - Starting forward pass.
2025-01-18 22:27:22,236 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:22,236 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:22,236 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:22,565 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:22,881 - DEBUG - Starting forward pass.
2025-01-18 22:27:22,881 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:22,882 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:22,882 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:23,208 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:23,526 - DEBUG - Starting forward pass.
2025-01-18 22:27:23,526 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:23,526 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:23,526 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:23,853 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:24,145 - DEBUG - Starting forward pass.
2025-01-18 22:27:24,146 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:24,146 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:24,146 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:24,470 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:24,744 - DEBUG - Starting forward pass.
2025-01-18 22:27:24,744 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:24,744 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:24,744 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:25,064 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:25,401 - DEBUG - Starting forward pass.
2025-01-18 22:27:25,402 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:25,402 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:25,402 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:25,727 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:26,028 - DEBUG - Starting forward pass.
2025-01-18 22:27:26,028 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:26,028 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:26,029 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:26,366 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:26,659 - DEBUG - Starting forward pass.
2025-01-18 22:27:26,660 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:26,660 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:26,660 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:26,990 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:27,290 - DEBUG - Starting forward pass.
2025-01-18 22:27:27,290 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:27,290 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:27,290 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:27,624 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:27,889 - DEBUG - Starting forward pass.
2025-01-18 22:27:27,889 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:27,889 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:27,889 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:28,214 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:28,498 - DEBUG - Starting forward pass.
2025-01-18 22:27:28,499 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:28,499 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:28,499 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:28,827 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:29,084 - DEBUG - Starting forward pass.
2025-01-18 22:27:29,085 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:29,085 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:29,085 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:29,412 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:29,693 - DEBUG - Starting forward pass.
2025-01-18 22:27:29,694 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:29,694 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:29,694 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:30,014 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:30,295 - DEBUG - Starting forward pass.
2025-01-18 22:27:30,295 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:30,295 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:30,295 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:30,619 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:30,907 - DEBUG - Starting forward pass.
2025-01-18 22:27:30,908 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:30,908 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:30,908 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:31,229 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:31,530 - DEBUG - Starting forward pass.
2025-01-18 22:27:31,530 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:31,530 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:31,530 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:31,857 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:32,150 - DEBUG - Starting forward pass.
2025-01-18 22:27:32,150 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:32,151 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:32,151 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:32,482 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:32,786 - DEBUG - Starting forward pass.
2025-01-18 22:27:32,787 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:32,787 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:32,787 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:33,107 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:33,400 - DEBUG - Starting forward pass.
2025-01-18 22:27:33,400 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:33,401 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:33,401 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:33,729 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:34,011 - DEBUG - Starting forward pass.
2025-01-18 22:27:34,011 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:34,011 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:34,012 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:34,341 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:34,633 - DEBUG - Starting forward pass.
2025-01-18 22:27:34,634 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:34,634 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:34,634 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:34,956 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:35,238 - DEBUG - Starting forward pass.
2025-01-18 22:27:35,238 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:35,238 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:35,238 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:35,567 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:35,863 - DEBUG - Starting forward pass.
2025-01-18 22:27:35,863 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:35,863 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:35,863 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:36,186 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:36,458 - DEBUG - Starting forward pass.
2025-01-18 22:27:36,458 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:36,458 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:36,458 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:36,790 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:37,121 - DEBUG - Starting forward pass.
2025-01-18 22:27:37,121 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:37,122 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:37,122 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:37,448 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:37,767 - DEBUG - Starting forward pass.
2025-01-18 22:27:37,768 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:37,768 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:37,768 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:38,096 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:38,389 - DEBUG - Starting forward pass.
2025-01-18 22:27:38,389 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:38,389 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:38,389 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:38,717 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:38,995 - DEBUG - Starting forward pass.
2025-01-18 22:27:38,995 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:38,996 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:38,996 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:39,326 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:39,619 - DEBUG - Starting forward pass.
2025-01-18 22:27:39,620 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:39,620 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:39,620 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:39,950 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:40,224 - DEBUG - Starting forward pass.
2025-01-18 22:27:40,224 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:40,225 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:40,225 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:40,555 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:40,857 - DEBUG - Starting forward pass.
2025-01-18 22:27:40,858 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:40,858 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:40,858 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:41,185 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:41,499 - DEBUG - Starting forward pass.
2025-01-18 22:27:41,499 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:41,499 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:41,500 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:41,832 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:42,109 - DEBUG - Starting forward pass.
2025-01-18 22:27:42,110 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:42,110 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:42,110 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:42,430 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:42,727 - DEBUG - Starting forward pass.
2025-01-18 22:27:42,727 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:42,728 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:42,728 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:43,055 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:43,357 - DEBUG - Starting forward pass.
2025-01-18 22:27:43,357 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:43,357 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:43,357 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:43,686 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:43,975 - DEBUG - Starting forward pass.
2025-01-18 22:27:43,976 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:43,976 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:43,976 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:44,308 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:44,595 - DEBUG - Starting forward pass.
2025-01-18 22:27:44,596 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:44,596 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:44,596 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:44,921 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:45,232 - DEBUG - Starting forward pass.
2025-01-18 22:27:45,233 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:45,233 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:45,233 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:45,565 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:45,884 - DEBUG - Starting forward pass.
2025-01-18 22:27:45,884 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:45,884 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:45,885 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:46,210 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:46,499 - DEBUG - Starting forward pass.
2025-01-18 22:27:46,499 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:46,500 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:46,500 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:46,817 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:47,142 - DEBUG - Starting forward pass.
2025-01-18 22:27:47,143 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:47,143 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:47,143 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:47,478 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:47,783 - DEBUG - Starting forward pass.
2025-01-18 22:27:47,783 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:47,784 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:47,784 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:48,115 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:48,422 - DEBUG - Starting forward pass.
2025-01-18 22:27:48,422 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:48,423 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:48,423 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:48,751 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:49,035 - DEBUG - Starting forward pass.
2025-01-18 22:27:49,036 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:49,036 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:49,036 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:49,359 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:49,643 - DEBUG - Starting forward pass.
2025-01-18 22:27:49,644 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:49,644 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:49,644 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:49,973 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:50,252 - DEBUG - Starting forward pass.
2025-01-18 22:27:50,252 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:50,253 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:50,253 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:50,562 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:50,842 - DEBUG - Starting forward pass.
2025-01-18 22:27:50,843 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:50,843 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:50,843 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:51,175 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:51,473 - DEBUG - Starting forward pass.
2025-01-18 22:27:51,473 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:51,473 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:51,474 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:51,799 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:52,120 - DEBUG - Starting forward pass.
2025-01-18 22:27:52,120 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:52,121 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:52,121 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:52,449 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:52,731 - DEBUG - Starting forward pass.
2025-01-18 22:27:52,732 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:52,732 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:52,732 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:53,066 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:53,351 - DEBUG - Starting forward pass.
2025-01-18 22:27:53,351 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:53,351 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:53,351 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:53,677 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:53,990 - DEBUG - Starting forward pass.
2025-01-18 22:27:53,990 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:53,991 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:53,991 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:54,319 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:54,598 - DEBUG - Starting forward pass.
2025-01-18 22:27:54,599 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:54,599 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:54,599 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:54,931 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:55,238 - DEBUG - Starting forward pass.
2025-01-18 22:27:55,239 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:55,239 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:55,240 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:55,573 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:55,889 - DEBUG - Starting forward pass.
2025-01-18 22:27:55,890 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:55,890 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:55,890 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:56,199 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:56,498 - DEBUG - Starting forward pass.
2025-01-18 22:27:56,499 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:56,499 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:56,499 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:56,827 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:57,127 - DEBUG - Starting forward pass.
2025-01-18 22:27:57,128 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:57,128 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:57,128 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:57,460 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:57,749 - DEBUG - Starting forward pass.
2025-01-18 22:27:57,749 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:57,750 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:57,750 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:58,081 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:58,363 - DEBUG - Starting forward pass.
2025-01-18 22:27:58,364 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:58,364 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:58,364 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:58,694 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:58,997 - DEBUG - Starting forward pass.
2025-01-18 22:27:58,998 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:58,998 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:58,998 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:59,327 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:27:59,632 - DEBUG - Starting forward pass.
2025-01-18 22:27:59,632 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:27:59,632 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:59,632 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:27:59,961 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:00,250 - DEBUG - Starting forward pass.
2025-01-18 22:28:00,251 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:00,251 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:00,251 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:00,582 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:00,897 - DEBUG - Starting forward pass.
2025-01-18 22:28:00,897 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:00,897 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:00,898 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:01,229 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:01,510 - DEBUG - Starting forward pass.
2025-01-18 22:28:01,510 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:01,510 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:01,510 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:01,830 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:02,149 - DEBUG - Starting forward pass.
2025-01-18 22:28:02,150 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:02,150 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:02,150 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:02,481 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:02,750 - DEBUG - Starting forward pass.
2025-01-18 22:28:02,751 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:02,751 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:02,751 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:03,081 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:03,373 - DEBUG - Starting forward pass.
2025-01-18 22:28:03,374 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:03,374 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:03,374 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:03,705 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:03,996 - DEBUG - Starting forward pass.
2025-01-18 22:28:03,996 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:03,996 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:03,996 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:04,328 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:04,629 - DEBUG - Starting forward pass.
2025-01-18 22:28:04,629 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:04,629 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:04,630 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:04,959 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:05,227 - DEBUG - Starting forward pass.
2025-01-18 22:28:05,227 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:05,228 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:05,228 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:05,557 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:05,856 - DEBUG - Starting forward pass.
2025-01-18 22:28:05,856 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:05,856 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:05,856 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:06,185 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:06,472 - DEBUG - Starting forward pass.
2025-01-18 22:28:06,472 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:06,472 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:06,472 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:06,795 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:07,097 - DEBUG - Starting forward pass.
2025-01-18 22:28:07,098 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:07,098 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:07,098 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:07,430 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:07,720 - DEBUG - Starting forward pass.
2025-01-18 22:28:07,720 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:07,721 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:07,721 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:08,050 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:08,339 - DEBUG - Starting forward pass.
2025-01-18 22:28:08,340 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:08,340 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:08,340 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:08,674 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:08,983 - DEBUG - Starting forward pass.
2025-01-18 22:28:08,984 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:08,984 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:08,984 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:09,307 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:09,618 - DEBUG - Starting forward pass.
2025-01-18 22:28:09,618 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:09,619 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:09,619 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:09,948 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:10,242 - DEBUG - Starting forward pass.
2025-01-18 22:28:10,242 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:10,242 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:10,242 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:10,571 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:10,880 - DEBUG - Starting forward pass.
2025-01-18 22:28:10,881 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:10,881 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:10,881 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:11,214 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:11,503 - DEBUG - Starting forward pass.
2025-01-18 22:28:11,503 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:11,504 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:11,504 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:11,820 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:12,132 - DEBUG - Starting forward pass.
2025-01-18 22:28:12,133 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:12,133 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:12,133 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:12,463 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:12,742 - DEBUG - Starting forward pass.
2025-01-18 22:28:12,743 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:12,743 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:12,743 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:13,074 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:13,370 - DEBUG - Starting forward pass.
2025-01-18 22:28:13,370 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:13,370 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:13,371 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:13,692 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:14,008 - DEBUG - Starting forward pass.
2025-01-18 22:28:14,008 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:14,009 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:14,009 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:14,335 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:14,614 - DEBUG - Starting forward pass.
2025-01-18 22:28:14,614 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:14,614 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:14,615 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:14,954 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:15,243 - DEBUG - Starting forward pass.
2025-01-18 22:28:15,243 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:15,244 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:15,244 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:15,570 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:15,890 - DEBUG - Starting forward pass.
2025-01-18 22:28:15,890 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:15,891 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:15,891 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:16,221 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:16,527 - DEBUG - Starting forward pass.
2025-01-18 22:28:16,528 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:16,528 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:16,528 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:16,862 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:17,164 - DEBUG - Starting forward pass.
2025-01-18 22:28:17,164 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:17,165 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:17,165 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:17,496 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:17,792 - DEBUG - Starting forward pass.
2025-01-18 22:28:17,793 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:17,793 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:17,793 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:18,121 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:18,422 - DEBUG - Starting forward pass.
2025-01-18 22:28:18,422 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:18,422 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:18,423 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:18,750 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:19,048 - DEBUG - Starting forward pass.
2025-01-18 22:28:19,049 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:19,049 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:19,049 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:19,378 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:19,688 - DEBUG - Starting forward pass.
2025-01-18 22:28:19,689 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:19,689 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:19,689 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:20,016 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:20,281 - DEBUG - Starting forward pass.
2025-01-18 22:28:20,281 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:20,281 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:20,281 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:20,603 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:20,899 - DEBUG - Starting forward pass.
2025-01-18 22:28:20,899 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:20,900 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:20,900 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:21,231 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:21,521 - DEBUG - Starting forward pass.
2025-01-18 22:28:21,521 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:21,522 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:21,522 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:21,844 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:22,147 - DEBUG - Starting forward pass.
2025-01-18 22:28:22,148 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:22,148 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:22,148 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:22,463 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:22,763 - DEBUG - Starting forward pass.
2025-01-18 22:28:22,763 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:22,763 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:22,763 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:23,088 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:23,410 - DEBUG - Starting forward pass.
2025-01-18 22:28:23,411 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:23,411 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:23,411 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:23,728 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:24,030 - DEBUG - Starting forward pass.
2025-01-18 22:28:24,030 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:24,031 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:24,031 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:24,363 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:24,673 - DEBUG - Starting forward pass.
2025-01-18 22:28:24,674 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:24,674 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:24,674 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:25,005 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:25,309 - DEBUG - Starting forward pass.
2025-01-18 22:28:25,309 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:25,310 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:25,310 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:25,650 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:25,966 - DEBUG - Starting forward pass.
2025-01-18 22:28:25,967 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:25,967 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:25,967 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:26,293 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:26,598 - DEBUG - Starting forward pass.
2025-01-18 22:28:26,598 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:26,598 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:26,599 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:26,926 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:27,230 - DEBUG - Starting forward pass.
2025-01-18 22:28:27,231 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:27,231 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:27,231 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:27,560 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:27,845 - DEBUG - Starting forward pass.
2025-01-18 22:28:27,846 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:27,846 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:27,846 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:28,178 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:28,479 - DEBUG - Starting forward pass.
2025-01-18 22:28:28,480 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:28,480 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:28,480 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:28,809 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:29,063 - DEBUG - Starting forward pass.
2025-01-18 22:28:29,063 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:29,064 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:29,064 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:29,391 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:29,686 - DEBUG - Starting forward pass.
2025-01-18 22:28:29,687 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:29,687 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:29,687 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:30,015 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:30,316 - DEBUG - Starting forward pass.
2025-01-18 22:28:30,317 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:30,317 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:30,317 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:30,648 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:30,960 - DEBUG - Starting forward pass.
2025-01-18 22:28:30,960 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:30,961 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:30,961 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:31,290 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:31,570 - DEBUG - Starting forward pass.
2025-01-18 22:28:31,570 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:31,571 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:31,571 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:31,901 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:32,208 - DEBUG - Starting forward pass.
2025-01-18 22:28:32,208 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:32,209 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:32,209 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:32,533 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:32,805 - DEBUG - Starting forward pass.
2025-01-18 22:28:32,806 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:32,806 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:32,806 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:33,136 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:33,461 - DEBUG - Starting forward pass.
2025-01-18 22:28:33,462 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:33,462 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:33,462 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:33,790 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:34,076 - DEBUG - Starting forward pass.
2025-01-18 22:28:34,077 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:34,077 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:34,077 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:34,401 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:34,705 - DEBUG - Starting forward pass.
2025-01-18 22:28:34,705 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:34,705 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:34,706 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:35,021 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:35,316 - DEBUG - Starting forward pass.
2025-01-18 22:28:35,316 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:35,317 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:35,317 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:35,648 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:35,949 - DEBUG - Starting forward pass.
2025-01-18 22:28:35,950 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:35,950 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:35,950 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:36,275 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:36,576 - DEBUG - Starting forward pass.
2025-01-18 22:28:36,576 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:36,577 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:36,577 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:36,899 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:37,210 - DEBUG - Starting forward pass.
2025-01-18 22:28:37,210 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:37,210 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:37,210 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:37,540 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:37,844 - DEBUG - Starting forward pass.
2025-01-18 22:28:37,844 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:37,844 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:37,844 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:38,171 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:38,469 - DEBUG - Starting forward pass.
2025-01-18 22:28:38,469 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:38,470 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:38,470 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:38,794 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:39,112 - DEBUG - Starting forward pass.
2025-01-18 22:28:39,113 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:39,113 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:39,113 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:39,445 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:39,751 - DEBUG - Starting forward pass.
2025-01-18 22:28:39,751 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:39,751 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:39,751 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:40,072 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:40,365 - DEBUG - Starting forward pass.
2025-01-18 22:28:40,366 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:40,366 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:40,366 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:40,695 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:40,990 - DEBUG - Starting forward pass.
2025-01-18 22:28:40,990 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:40,990 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:40,990 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:41,311 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:41,607 - DEBUG - Starting forward pass.
2025-01-18 22:28:41,608 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:41,608 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:41,608 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:41,938 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:42,242 - DEBUG - Starting forward pass.
2025-01-18 22:28:42,242 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:42,242 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:42,242 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:42,564 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:42,865 - DEBUG - Starting forward pass.
2025-01-18 22:28:42,865 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:42,865 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:42,865 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:43,195 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:43,493 - DEBUG - Starting forward pass.
2025-01-18 22:28:43,494 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:43,494 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:43,494 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:43,819 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:44,129 - DEBUG - Starting forward pass.
2025-01-18 22:28:44,129 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:44,130 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:44,130 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:44,458 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:44,765 - DEBUG - Starting forward pass.
2025-01-18 22:28:44,766 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:44,766 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:44,766 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:45,090 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:45,346 - DEBUG - Starting forward pass.
2025-01-18 22:28:45,346 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:45,347 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:45,347 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:45,674 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:45,983 - DEBUG - Starting forward pass.
2025-01-18 22:28:45,984 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:45,984 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:45,984 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:46,315 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:46,606 - DEBUG - Starting forward pass.
2025-01-18 22:28:46,607 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:46,607 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:46,607 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:46,928 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:47,210 - DEBUG - Starting forward pass.
2025-01-18 22:28:47,211 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:47,211 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:47,212 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:47,543 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:47,860 - DEBUG - Starting forward pass.
2025-01-18 22:28:47,861 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:47,861 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:47,861 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:48,185 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:48,476 - DEBUG - Starting forward pass.
2025-01-18 22:28:48,476 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:48,476 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:48,476 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:48,797 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:49,115 - DEBUG - Starting forward pass.
2025-01-18 22:28:49,115 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:49,116 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:49,116 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:49,442 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:49,737 - DEBUG - Starting forward pass.
2025-01-18 22:28:49,738 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:49,738 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:49,738 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:50,071 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:50,348 - DEBUG - Starting forward pass.
2025-01-18 22:28:50,349 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:50,349 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:50,349 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:50,668 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:50,980 - DEBUG - Starting forward pass.
2025-01-18 22:28:50,980 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:50,981 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:50,981 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:51,306 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:51,578 - DEBUG - Starting forward pass.
2025-01-18 22:28:51,578 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:51,578 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:51,579 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:51,909 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:52,205 - DEBUG - Starting forward pass.
2025-01-18 22:28:52,206 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:52,206 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:52,206 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:52,528 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:52,829 - DEBUG - Starting forward pass.
2025-01-18 22:28:52,829 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:52,829 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:52,830 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:53,164 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:53,477 - DEBUG - Starting forward pass.
2025-01-18 22:28:53,477 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:53,478 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:53,478 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:53,807 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:54,120 - DEBUG - Starting forward pass.
2025-01-18 22:28:54,120 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:54,121 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:54,121 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:54,450 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:54,731 - DEBUG - Starting forward pass.
2025-01-18 22:28:54,732 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:54,732 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:54,732 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:55,061 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:55,325 - DEBUG - Starting forward pass.
2025-01-18 22:28:55,325 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:55,325 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:55,326 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:55,647 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:55,913 - DEBUG - Starting forward pass.
2025-01-18 22:28:55,913 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:55,913 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:55,913 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:56,239 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:56,507 - DEBUG - Starting forward pass.
2025-01-18 22:28:56,508 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:56,508 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:56,508 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:56,817 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:57,103 - DEBUG - Starting forward pass.
2025-01-18 22:28:57,103 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:57,103 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:57,103 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:57,420 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:57,722 - DEBUG - Starting forward pass.
2025-01-18 22:28:57,723 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:57,723 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:57,723 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:58,054 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:58,365 - DEBUG - Starting forward pass.
2025-01-18 22:28:58,365 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:58,366 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:58,366 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:58,694 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:58,983 - DEBUG - Starting forward pass.
2025-01-18 22:28:58,983 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:58,983 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:58,983 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:59,314 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:28:59,605 - DEBUG - Starting forward pass.
2025-01-18 22:28:59,605 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:28:59,605 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:59,605 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:28:59,942 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:00,254 - DEBUG - Starting forward pass.
2025-01-18 22:29:00,255 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:00,255 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:00,255 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:00,575 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:00,885 - DEBUG - Starting forward pass.
2025-01-18 22:29:00,886 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:00,886 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:00,886 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:01,208 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:01,507 - DEBUG - Starting forward pass.
2025-01-18 22:29:01,508 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:01,508 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:01,508 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:01,818 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:02,111 - DEBUG - Starting forward pass.
2025-01-18 22:29:02,111 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:02,112 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:02,112 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:02,448 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:02,746 - DEBUG - Starting forward pass.
2025-01-18 22:29:02,746 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:02,746 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:02,746 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:03,051 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:03,360 - DEBUG - Starting forward pass.
2025-01-18 22:29:03,360 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:03,360 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:03,360 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:03,685 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:03,969 - DEBUG - Starting forward pass.
2025-01-18 22:29:03,969 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:03,969 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:03,969 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:04,300 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:04,611 - DEBUG - Starting forward pass.
2025-01-18 22:29:04,612 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:04,612 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:04,612 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:04,931 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:05,247 - DEBUG - Starting forward pass.
2025-01-18 22:29:05,248 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:05,248 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:05,248 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:05,576 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:05,877 - DEBUG - Starting forward pass.
2025-01-18 22:29:05,878 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:05,878 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:05,878 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:06,208 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:06,498 - DEBUG - Starting forward pass.
2025-01-18 22:29:06,499 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:06,499 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:06,499 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:06,829 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:07,129 - DEBUG - Starting forward pass.
2025-01-18 22:29:07,129 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:07,130 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:07,130 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:07,442 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:07,717 - DEBUG - Starting forward pass.
2025-01-18 22:29:07,717 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:07,717 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:07,717 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:08,043 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:08,345 - DEBUG - Starting forward pass.
2025-01-18 22:29:08,346 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:08,346 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:08,346 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:08,676 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:08,956 - DEBUG - Starting forward pass.
2025-01-18 22:29:08,957 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:08,957 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:08,957 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:09,289 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:09,626 - DEBUG - Starting forward pass.
2025-01-18 22:29:09,626 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:09,627 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:09,627 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:09,952 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:10,229 - DEBUG - Starting forward pass.
2025-01-18 22:29:10,229 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:10,230 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:10,230 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:10,537 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:10,838 - DEBUG - Starting forward pass.
2025-01-18 22:29:10,838 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:10,839 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:10,839 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:11,167 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:11,473 - DEBUG - Starting forward pass.
2025-01-18 22:29:11,473 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:11,474 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:11,474 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:11,794 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:12,105 - DEBUG - Starting forward pass.
2025-01-18 22:29:12,105 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:12,106 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:12,106 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:12,433 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:12,707 - DEBUG - Starting forward pass.
2025-01-18 22:29:12,708 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:12,708 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:12,708 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:13,045 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:13,357 - DEBUG - Starting forward pass.
2025-01-18 22:29:13,357 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:13,358 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:13,358 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:13,686 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:13,954 - DEBUG - Starting forward pass.
2025-01-18 22:29:13,955 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:13,955 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:13,955 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:14,287 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:14,600 - DEBUG - Starting forward pass.
2025-01-18 22:29:14,601 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:14,601 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:14,601 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:14,929 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:15,238 - DEBUG - Starting forward pass.
2025-01-18 22:29:15,238 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:15,238 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:15,239 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:15,563 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:15,865 - DEBUG - Starting forward pass.
2025-01-18 22:29:15,865 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:15,865 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:15,865 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:16,186 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:16,490 - DEBUG - Starting forward pass.
2025-01-18 22:29:16,491 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:16,491 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:16,491 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:16,819 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:17,144 - DEBUG - Starting forward pass.
2025-01-18 22:29:17,145 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:17,145 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:17,145 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:17,473 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:17,770 - DEBUG - Starting forward pass.
2025-01-18 22:29:17,771 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:17,771 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:17,771 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:18,102 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:18,398 - DEBUG - Starting forward pass.
2025-01-18 22:29:18,399 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:18,399 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:18,399 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:18,734 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:19,038 - DEBUG - Starting forward pass.
2025-01-18 22:29:19,038 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:19,038 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:19,038 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:19,369 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:19,650 - DEBUG - Starting forward pass.
2025-01-18 22:29:19,650 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:19,651 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:19,651 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:19,981 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:20,288 - DEBUG - Starting forward pass.
2025-01-18 22:29:20,288 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:20,289 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:20,289 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:20,631 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:20,939 - DEBUG - Starting forward pass.
2025-01-18 22:29:20,939 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:20,939 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:20,939 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:21,264 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:21,568 - DEBUG - Starting forward pass.
2025-01-18 22:29:21,568 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:21,568 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:21,569 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:21,894 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:22,198 - DEBUG - Starting forward pass.
2025-01-18 22:29:22,198 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:22,199 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:22,199 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:22,529 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:22,821 - DEBUG - Starting forward pass.
2025-01-18 22:29:22,821 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:22,821 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:22,821 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:23,143 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:23,445 - DEBUG - Starting forward pass.
2025-01-18 22:29:23,445 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:23,446 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:23,446 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:23,773 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:24,074 - DEBUG - Starting forward pass.
2025-01-18 22:29:24,075 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:24,075 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:24,075 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:24,406 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:24,720 - DEBUG - Starting forward pass.
2025-01-18 22:29:24,721 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:24,721 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:24,721 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:25,040 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:25,349 - DEBUG - Starting forward pass.
2025-01-18 22:29:25,349 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:25,349 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:25,349 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:25,661 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:25,943 - DEBUG - Starting forward pass.
2025-01-18 22:29:25,944 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:25,944 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:25,944 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:26,273 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:26,561 - DEBUG - Starting forward pass.
2025-01-18 22:29:26,562 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:26,562 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:26,562 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:26,893 - ERROR - Error processing batch in train phase: CUDA out of memory. Tried to allocate 13.08 GiB. GPU 0 has a total capacity of 23.68 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-18 22:29:27,217 - DEBUG - Starting forward pass.
2025-01-18 22:29:27,217 - DEBUG - Padded input tensor shape: torch.Size([8, 3, 18, 114, 114])
2025-01-18 22:29:27,217 - DEBUG - Extracted patches shape: torch.Size([8, 3, 27, 16, 112, 112])
2025-01-18 22:29:27,218 - DEBUG - Extracted patches for Volterra approximation, shape: torch.Size([8, 3, 27, 16, 112, 112])
